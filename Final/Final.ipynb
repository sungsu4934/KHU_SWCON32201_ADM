{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "f702joOHTf2B",
    "outputId": "0a4ca8db-5d44-4fb1-a2e2-25ce4ea37c31"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df16 = pd.read_sas('hn16_all.sas7bdat')\n",
    "df16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "qpq4nBZJUSia",
    "outputId": "426b621f-918f-4d7c-f536-79b176c3b6e1"
   },
   "outputs": [],
   "source": [
    "df17 = pd.read_sas('hn17_all.sas7bdat')\n",
    "df17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "XjqaCLMPUWEL",
    "outputId": "71448365-ad27-4185-ad03-4482a2d5b96b"
   },
   "outputs": [],
   "source": [
    "df18 = pd.read_sas('hn18_all.sas7bdat')\n",
    "df18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dl8B9sbtVto-"
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df16,df17,df18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMRWlSWMT0Gs"
   },
   "outputs": [],
   "source": [
    "df_att = df_all[[\"sex\",\"age\",\"D_1_1\",\"Total_slp_wk\",\"BP1\",\"BO1\",\"BE5_1\",\"BE8_1\",\"BE8_2\",\"BP5\",\"HE_ht\",\"HE_wt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "KNP4PPeAl92H",
    "outputId": "716cc5a8-a29c-4314-fe0e-bb395360d33a"
   },
   "outputs": [],
   "source": [
    "df_att.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "id": "hm3qyH2SW6ji",
    "outputId": "3996a031-2bd1-4832-c687-c6943a57632b"
   },
   "outputs": [],
   "source": [
    "# BMI [BMI] (명목) 변수 생성\n",
    "df_att['BMI'] = (df_att['HE_wt'] / (df_att['HE_ht'] / 100)**2)\n",
    "df_att.loc[df_att['BMI'] < 25, 'BMI'] = 0\n",
    "df_att.loc[df_att['BMI'] >= 25, 'BMI'] = 1\n",
    "print(df_att['BMI'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['BMI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "0pXR8rlb3R74",
    "outputId": "2b63360d-7090-4b23-b8af-b148d503cd4c"
   },
   "outputs": [],
   "source": [
    "df_csn = df_att.loc[(df_att['age']>=12) & (df_att['age']<=18), :]  # 청소년 (만12세~18세) 데이터 생성\n",
    "df_csn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "5c26HlGYW2il",
    "outputId": "527946b1-97cb-43d0-d32a-83493187ebbc"
   },
   "outputs": [],
   "source": [
    "# 하루 평균 앉아서 보내는 시간(분 단위) 변수 생성\n",
    "df_csn[\"SitTime\"] = df_csn[\"BE8_1\"]*60 + df_csn['BE8_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "hHcBmCb03Za8",
    "outputId": "1c376be6-e26a-40c6-d5bf-471def7c9599"
   },
   "outputs": [],
   "source": [
    "df_cgh = pd.read_csv('cgh18.csv')\n",
    "a= df_cgh.iloc[:,1:]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqIcgmkG3a2W"
   },
   "outputs": [],
   "source": [
    "df_att = pd.concat([df_csn,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nss6l1pi3BW6"
   },
   "outputs": [],
   "source": [
    "df_att['BMI'] = df_att['BMI'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPKl3Z7jWy5t"
   },
   "outputs": [],
   "source": [
    "df_att.loc[(df_att['BE8_1'] == 88) |(df_att['BE8_1'] == 99) , 'BE8_1'] = np.nan \n",
    "df_att.loc[(df_att['BE8_2'] == 88) |(df_att['BE8_2'] == 99) , 'BE8_2'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "o9mSA5T1W0HL",
    "outputId": "b6929467-61d0-4729-cd68-a8f62ffa6426"
   },
   "outputs": [],
   "source": [
    "print(df_att['BE8_1'].value_counts())\n",
    "print(\"=\"*14)\n",
    "print(df_att['BE8_2'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요 Attribute만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bL7j_0T-T-iq"
   },
   "outputs": [],
   "source": [
    "df_att = df_att.loc[:,['sex','age','D_1_1','BP1','BO1','BE5_1','BP5','BMI','Total_slp_wk','SitTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "_QTy76DaXOkj",
    "outputId": "edda639f-116d-4b69-842e-1831bfbb6ece"
   },
   "outputs": [],
   "source": [
    "# 1주일간 근력운동 일수 (등간)\n",
    "print(df_att['BE5_1'].value_counts()) # 8 비해당 929명, 9 모름, 무응답 : 267명 -> NA\n",
    "df_att.loc[(df_att['BE5_1'] == 8) |(df_att['BE5_1'] == 9) , 'BE5_1'] = np.nan  #na 값 처리\n",
    "print(df_att['BE5_1'].value_counts())\n",
    "#df_att['BE5_1'].astype('int64') # na 제거하거나 대체하면 에러 안남. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "VGN4rMhhWaag",
    "outputId": "6ed27141-d355-4611-b5be-a1dd9ae848b6"
   },
   "outputs": [],
   "source": [
    "# 주관적 건강상태 [D_1_1]] (순서)\n",
    "from pandas.api.types import CategoricalDtype\n",
    "print(df_att['D_1_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_att.loc[df_att['D_1_1'] == 9, 'D_1_1'] = np.nan\n",
    "df_att['D_1_1'] = df_att['D_1_1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_att['D_1_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['D_1_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "6DorAQSzWqk4",
    "outputId": "7280c848-564f-4f4f-b505-b39161012816"
   },
   "outputs": [],
   "source": [
    "# 2주 이상 연속 우울감 여부 [BP5] (명목)\n",
    "print(df_att['BP5'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_att.loc[df_att['BP5'] == 8, 'BP5'] = np.nan\n",
    "df_att.loc[df_att['BP5'] == 9, 'BP5'] = np.nan\n",
    "df_att['BP5'] = df_att['BP5'].astype('category')\n",
    "print(df_att['BP5'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['BP5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "q2B2bxVPXU8r",
    "outputId": "eb53e705-84d3-4694-d39c-cbb4f9b7f33d"
   },
   "outputs": [],
   "source": [
    "# 평소 스트레스 인지정도 [BP1] (순서)\n",
    "from pandas.api.types import CategoricalDtype\n",
    "print(df_att['BP1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_att.loc[df_att['BP1'] == 8, 'BP1'] = np.nan\n",
    "df_att.loc[df_att['BP1'] == 9, 'BP1'] = np.nan\n",
    "\n",
    "df_att['BP1'] = df_att['BP1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_att['BP1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['BP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "yoZvgF9qXWCJ",
    "outputId": "b36ae381-3b4f-469e-9eb2-1d37e5ebf14b"
   },
   "outputs": [],
   "source": [
    "# 주관적 체형 인지 [BO1] (순서)\n",
    "from pandas.api.types import CategoricalDtype\n",
    "print(df_att['BO1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_att.loc[df_att['BO1'] == 8, 'BO1'] = np.nan\n",
    "df_att.loc[df_att['BO1'] == 9, 'BO1'] = np.nan\n",
    "\n",
    "df_att['BO1'] = df_att['BO1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_att['BO1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['BO1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "LC0nMDuL4OtF",
    "outputId": "b0329e3b-3fc7-4128-fb7e-8585919a0f3c"
   },
   "outputs": [],
   "source": [
    "# 1주일간 근력운동 일수 [BE5_1]] (순서)\n",
    "from pandas.api.types import CategoricalDtype\n",
    "print(df_att['BE5_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_att['BE5_1'] = df_att['BE5_1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_att['BE5_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['BE5_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "bOFM7ilAXXF3",
    "outputId": "1fc96ade-7098-4061-b1a3-8ffa2dfe7e4a"
   },
   "outputs": [],
   "source": [
    "df_att['sex'] = df_att['sex'].astype('category')\n",
    "df_att.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFjL09BdlkYu"
   },
   "source": [
    "# 결측치 처리\n",
    "### 전체: df_all\n",
    "### 남자: df_all_b\n",
    "### 여자: df_all_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "e0sr7hC8li9H",
    "outputId": "6e7479b2-b12e-4dad-8885-55141122bb95"
   },
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "df_new = df_att.dropna(axis=0)\n",
    "df_new = df_new.reset_index()\n",
    "df_all = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#남자 먹이기\n",
    "df_all_b = df_all.loc[df_all[\"sex\"]==1,:]\n",
    "df_all_b = df_all_b.drop('sex', axis = 1)\n",
    "\n",
    "df_all_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DU자 먹이기\n",
    "df_all_g = df_all.loc[df_all[\"sex\"]==2,:]\n",
    "df_all_g = df_all_g.drop('sex', axis = 1)\n",
    "\n",
    "df_all_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.iloc[:,1:11]\n",
    "df_all_g = df_all_g.iloc[:,1:11]\n",
    "df_all_b = df_all_b.iloc[:,1:11]\n",
    "\n",
    "df_all.shape, df_all_b.shape, df_all_g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outlier 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(d_cp, column):\n",
    "    fraud_column_data = d_cp[column]\n",
    "    quan_25 = np.percentile(fraud_column_data, 25)\n",
    "    quan_75 = np.percentile(fraud_column_data, 75)\n",
    "    \n",
    "    iqr = quan_75 - quan_25\n",
    "    iqr = iqr * 1.5\n",
    "    lowest = quan_25 - iqr\n",
    "    highest = quan_75 + iqr\n",
    "    outlier_index = fraud_column_data[(fraud_column_data<lowest) | (fraud_column_data > highest)].index\n",
    "    d_cp.drop(outlier_index, axis=0, inplace=True)\n",
    "    return d_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.shape)\n",
    "df_all = remove_outlier(df_all, 'SitTime')\n",
    "df_all = remove_outlier(df_all, 'Total_slp_wk')\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all_g.shape)\n",
    "df_all_g = remove_outlier(df_all_g, 'SitTime')\n",
    "df_all_g = remove_outlier(df_all_g, 'Total_slp_wk')\n",
    "print(df_all_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all_b.shape)\n",
    "df_all_b = remove_outlier(df_all_b, 'SitTime')\n",
    "df_all_b = remove_outlier(df_all_b, 'Total_slp_wk')\n",
    "print(df_all_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수중요도 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test 나누기와 업샘플링 그리고 scaling\n",
    "def train_test_split_and_upsample(df_input, scaling):\n",
    "    \n",
    "    df = df_input.copy()\n",
    "    \n",
    "    df = df.astype('category')\n",
    "    df['SitTime'] = df['SitTime'].astype('float64')\n",
    "    df['Total_slp_wk'] = df['Total_slp_wk'].astype('float64')\n",
    "    df['age'] = df['age'].astype('float64')\n",
    "    \n",
    "    df_class_0 = df[df['BMI'] == 0]\n",
    "    df_class_1 = df[df['BMI'] == 1]\n",
    "    \n",
    "    df_class_1_over = df_class_1.sample(df_class_0.shape[0], replace=True, random_state=10)\n",
    "    df_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "    \n",
    "    feature_columns = list(df.columns.difference(['BMI']))\n",
    "    X = df[feature_columns]\n",
    "    y = df[['BMI']]\n",
    "    \n",
    "    X_res = df_over[feature_columns]\n",
    "    y_res = df_over[['BMI']]\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import preprocessing\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y) \n",
    "    train_x_res, test_x_res, train_y_res, test_y_res = train_test_split(X_res, y_res, test_size = 0.3, random_state = 0, stratify = y_res)\n",
    "    \n",
    "    train_x = train_x.reset_index().iloc[:,1:]\n",
    "    tmp2 = train_x.loc[:,['Total_slp_wk', 'SitTime']]\n",
    "    train_x = train_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "    train_x = pd.concat([train_x, tmp2], axis=1)\n",
    "\n",
    "    test_x = test_x.reset_index().iloc[:,1:]\n",
    "    tmp2 = test_x.loc[:,['Total_slp_wk', 'SitTime']]\n",
    "    test_x = test_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "    test_x = pd.concat([test_x, tmp2], axis=1)\n",
    "\n",
    "    train_y = train_y.reset_index()['BMI']\n",
    "    \n",
    "    test_y = test_y.reset_index()['BMI']\n",
    "    \n",
    "    train_x_res = train_x_res.reset_index().iloc[:,1:]\n",
    "    tmp2 = train_x_res.loc[:,['Total_slp_wk', 'SitTime']]\n",
    "    train_x_res = train_x_res.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "    train_x_res = pd.concat([train_x_res, tmp2], axis=1)\n",
    "\n",
    "    train_y_res = train_y_res.reset_index()['BMI']\n",
    "    \n",
    "    if scaling == True:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp = min_max_scaler.fit_transform(train_x.loc[:,['Total_slp_wk','SitTime']])\n",
    "        temp = pd.DataFrame(temp, columns = ['Total_slp_wk','SitTime'])\n",
    "        train_x = train_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "        train_x = pd.concat([train_x, temp], axis=1)\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp = min_max_scaler.fit_transform(test_x.loc[:,['Total_slp_wk','SitTime']])\n",
    "        temp = pd.DataFrame(temp, columns = ['Total_slp_wk','SitTime'])\n",
    "        test_x = test_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "        test_x = pd.concat([test_x, temp], axis=1)\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp = min_max_scaler.fit_transform(train_x_res.loc[:,['Total_slp_wk','SitTime']])\n",
    "        temp = pd.DataFrame(temp, columns = ['Total_slp_wk','SitTime'])\n",
    "        train_x_res = train_x_res.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "        train_x_res = pd.concat([train_x_res, temp], axis=1)    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #train = pd.concat([train_x, train_y], axis=1)\n",
    "    #train_res = pd.concat([train_x_res, train_y_res], axis=1)\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y, train_x_res, train_y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA실시한 열을 만드는 함수\n",
    "\n",
    "def make_pca_col(train_data):\n",
    "    train_x = train_data.copy()\n",
    "    train_x_pca = train_x[['age','Total_slp_wk','SitTime']]\n",
    "    train_x = train_x.drop(['age','Total_slp_wk','SitTime'], axis=1)\n",
    "    pca = PCA(random_state=0, n_components=1)\n",
    "    train_x_pca = pca.fit_transform(train_x_pca)\n",
    "    train_x_pca = pd.Series(train_x_pca.reshape(-1))\n",
    "    train_x = pd.concat([train_x, train_x_pca], axis=1)\n",
    "    train_x.rename(columns = {0 : 'PCA_col'}, inplace = True)\n",
    "    \n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 출력 함수\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    F2_Score = (5 * Recall * Precision) / (Recall + 4*Precision)\n",
    "    \n",
    "    print(\"Accuracy: \", round(Accuracy,3))\n",
    "    print(\"Precision: \", round(Precision,3))\n",
    "    print(\"Recall: \", round(Recall,3))\n",
    "    #print(\"Specificity: \", round(Specificity,3))\n",
    "    #print(\"F1-Score: \", round(F1_Score,3))\n",
    "    print(\"F2-Score: \", round(F2_Score,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 탐색적 데이터분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test/oversample_train 분류\n",
    "tmp = train_test_split_and_upsample(df_all, scaling=False) \n",
    "train_x = tmp[0]\n",
    "train_y = tmp[2]\n",
    "test_x = tmp[1]\n",
    "test_y = tmp[3]\n",
    "train_x_res = tmp[4]\n",
    "train_y_res = tmp[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버 샘플링된 데이터 합치기\n",
    "over = pd.concat([train_x, train_y], axis=1)\n",
    "over.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. BE5_1\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['BE5_1'])\n",
    "plt.title('Histogram of BE5_1')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. BO1\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['BO1'])\n",
    "plt.title('Histogram of BO1')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. BP1\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['BP1'])\n",
    "plt.title('Histogram of BP1')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. BP5\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['BP5'])\n",
    "plt.title('Histogram of BP5')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. D_1_1\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['D_1_1'])\n",
    "plt.title('Histogram of D_1_1')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. age\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['age'],bins=6)\n",
    "plt.title('Histogram of age')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. sex\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['sex'])\n",
    "plt.title('Histogram of sex')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Total_slp_wk\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['Total_slp_wk'], bins=30)\n",
    "plt.title('Histogram of Total_slp_wk')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. SitTime\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['SitTime'], bins=60)\n",
    "plt.title('Histogram of Scatter of SitTime')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. BMI\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(over['BMI'])\n",
    "plt.title('Histogram of BMI')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA 모델링 및 RF 그리드서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all 대신 df_all_b, df_all_g를 넣으면 걔네들에 대해서 트레인, 테스트, 오버샘플링 출력\n",
    "tmp = train_test_split_and_upsample(df_all_g, scaling=False) \n",
    "train_x = tmp[0]\n",
    "train_y = tmp[2]\n",
    "test_x = tmp[1]\n",
    "test_y = tmp[3]\n",
    "train_x_res = tmp[4]\n",
    "train_y_res = tmp[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#내가 원하는 기존train또는 oversample된 train을 구하기\n",
    "\n",
    "#train_x = train_x_res.copy()\n",
    "#train_y = train_y_res.copy()\n",
    "\n",
    "train_x = make_pca_col(train_x_res)\n",
    "train_y = train_y_res.copy()\n",
    "test_x = make_pca_col(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF 그리드서치 \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "#rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "#rf.fit(X_train, y_train)\n",
    "\n",
    "#최적 파라미터 값 찾기\n",
    "params = { 'n_estimators' : [10, 100],\n",
    "           'max_depth' : [6, 8, 10, 12],\n",
    "           'min_samples_leaf' : [8, 12, 18],\n",
    "           'min_samples_split' : [8, 16, 20]\n",
    "            }\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 10, n_jobs = -1, scoring='neg_mean_squared_error')\n",
    "grid_cv.fit(train_x, train_y)\n",
    "\n",
    "predicted = grid_cv.predict(test_x)\n",
    "predicted_proba = grid_cv.predict_proba(test_x)\n",
    "\n",
    "pred_y_proba = []\n",
    "pred_y_proba_list = grid_cv.predict_proba(test_x)\n",
    "for i in range(pred_y_proba_list.shape[0]):\n",
    "    pred_y_proba.append(pred_y_proba_list[i][1])\n",
    "\n",
    "# AUC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_y, pred_y_proba)\n",
    "\n",
    "# Print ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "\n",
    "# Print AUC\n",
    "auc = np.trapz(tpr,fpr)\n",
    "\n",
    "\n",
    "print(confusion_matrix(test_y, predicted))\n",
    "print(model_evaluation(test_y, predicted))\n",
    "print('AUC:', round(auc,3))\n",
    "plt.plot(fpr,tpr)\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "#print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수중요도 추출1\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance \n",
    "\n",
    "perm = PermutationImportance(grid_cv, random_state = 0).fit(train_x, train_y) \n",
    "df_impt = eli5.show_weights(perm, top = 80, feature_names = train_x.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수중요도 시각화\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "result = permutation_importance(grid_cv, train_x, train_y, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "plt.barh(train_x.columns[sorted_idx], sorted(result.importances_mean))\n",
    "plt.title('Permutation Importance', fontsize=18)\n",
    "plt.ylabel('Feature name', fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "plz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
